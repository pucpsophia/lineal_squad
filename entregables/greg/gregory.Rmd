---
title: "Maestria en Estadistica - Modelos Lineales"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)


library(MASS)
library(car)
library("PerformanceAnalytics")
library(lmtest)
library(glmnet)
library(planor)
library(multcomp)


# set working directory
#setwd("/Users/gvalderrama/Documents/pucp/lineal_squad/entregables/greg")
#setwd("/Users/gregory/Documents/pucp/lineal_squad/entregables/greg")
setwd("F:/lineal_squad/entregables/greg")

```

# *Gregory Valderrama - 20133303* 

Las tildes y caracteres en espaniol fueron omitidos por imcompatibilidades tecnicas.

## **Pregunta 1** 
Demuestre que la varianza del estimador de $I^2$ por maximos cuadrados generalizados es $Var(\hat{B})=\sigma^2(X^TV^{-1}X)^{-1}$
realize la demostracion paso a paso detallando las propiedades utilizadas.

## **Pregunta 2** 
Suponga que deseamos ajustar un modelo de regresion sin intercepto con maximos cuadrados ponderados. Suponer que las observaciones son no correlacionadas, pero que tienen varianzas desiguales.

a) Deducir una formula general para el estimador de $\beta$ por maximos cuadrados ponderados. 

b) øCual es la varianza del estimador del item anterior?

## **Pregunta 3** 

El conjunto de datos sobre la medicion estandarizada de la fecundidad e indicadores socioeconomicos para cada una de las 47 provincias francofonas de Suiza alrededor del anhio 1888 se encuentran disponibles en R bajo el nombre swiss. Este conjunto de datos cuenta con 47 observaciones sobre 6 variables, cada una de las cuales est√° en porcentaje, es decir, en [0, 100].
Realice un analisis descriptivo y luego ajuste un modelo de regresion lineal considerando como variable respuesta la variable fertilidad y el resto como covariables. Verifique si el modelo cumple con los supuestos. Corrija el problema de multicolinealidad con las t√©cnicas estudiadas en clase e interprete los resultados del modelo final. Para cargar el conjunto de datos use el comando data(swiss) en el R.

### *Descripcion de datos*

* $\textbf{Fertility }$ Ig. medida comun de fertilidad estandarizada

* $\textbf{Agriculture }$ % de hombres involucrados en la agricultura como ocupacion

* $\textbf{Examination }$ % de reclutas que reciben la calificacion mas alta en el examen del ejercito

* $\textbf{Education }$ % educacion mas all? de la escuela primaria para reclutas.

* $\textbf{Catholic }$ % 'catolico' (a diferencia de 'protestante').

* $\textbf{Infant.Mortality }$ nacidos vivos que viven menos de 1 anhio.

```{r} 
data(swiss)
colnames(swiss)
str(swiss)
summary(swiss)
data_scaled <- as.data.frame(scale(swiss))
boxplot(data_scaled)
```

#### *Regresion lineal*

```{r }
lm1 <- lm(formula = Fertility ~ ., data = swiss)
summary(lm1)

```

Lo primera observacion es que tenemos un buen modelo y hay varias variables (la mayoria) con una buena
significancia. Un punto que no deberia suceder pero siempre ocurre es que el intercepto no es 0, esto podria
causar que los valores estimados de Fertilidad salgan menores a 0, lo cual en la realidad seria imposible pues no
se puede recaudar negativo.

```{r}
lm1 <- lm(formula = Fertility ~ ., data = swiss)
lm1$coefficients
```
Lo que significan estos coeficientes, por ejemplo el ultimo de la lista Infant.Mortality nos dice que si todas las otros
otros regresores se mantuvieran constantes y solamente ese cambiara en una unidad, el Fertility se ver?a
afectado en 1.07705. 


#### *Analizado los graficos de la regresion, Valores reales vs valores estimados*

```{r}
lm1 <- lm(formula = Fertility ~ ., data = swiss)
plot(lm1$fitted.values, swiss$Fertility)
abline(0, 1, col = 2)
```

#### Supuestos

**Grafico de los residuos - homocedasticidad**

La figura nos permite evaluar la hipotesis de homocedasticidad de los residuos,
sera aceptable cuando la anchura horizontal del grafico se mantenga razonablemente
constante. 

Si el p-value del test de Breusch-Pagan es mayor que 0.05 entonces aceptamos la hipotesis
nula (la varianza de todos los grupos son iguales) y decimos que cumple el
supuesto de homocedasticidad, caso contrario no se cumple el supuesto de homocedasticidad
de varianzas. Podemos ver que se acepta la homocedasticidad.


```{r}
lm1 <- lm(formula = Fertility ~ ., data = swiss)

ncvTest(lm1)

plot(lm1, which=c(3))
```


**Efecto de las variables independientes en la variable dependiente es lineal**

```{r}
par(mfrow=c(1,1))
plot(lm1, which=c(1))

```

**Normalidad de los errores**

Los errores residuales son normales y normalmente distribuidos con media cero.
Aplicando el test de Shapiro-Wilk se probara si se cumple o no el supuesto de normalidad de los
residuos. Con un valor de 0.93 probamos la normalidad de los datos.


```{r}

shapiro.test(lm1$residuals)

par(mfrow=c(1,1))
plot(lm1, which=c(2))

```
**Los errores no estan correlacionados**

Autocorrelacion significa la correlacion de los valores de una misma variable ordenados en el tiempo (con datos de
series temporales) o en el espacio (con datos espaciales). 

```{r}

dwtest(lm1)

par(mfrow=c(1,1))
plot(lm1, which=c(3))

```


**Multicolinealidad de los regresores es minima**

Buscaremos variables que esten correlacionadas con las demas y que, por ello, no esten aportando mas al modelo y que podrian estar distorsionando las predicciones generando overfitting.

```{r}

vif(lm1)
chart.Correlation(swiss, histogram=FALSE, pch=19)

```

Como podemos apreciar existe una correlacion entre las variables Examination y Education, para revizar la performance de la prediccion
del modelo, compararemos el $R^2$ con los metodos RIDGE y LASSO para ver si podemos obtener una mejor precision. Dividimos el conjunto de datos en un grupo de entrenamiento y otro de validacion. 

```{r}

set.seed(1)

x = model.matrix(Fertility~., swiss)[, -c(1)] # matriz de covariables
y = swiss$Fertility                           # vector respuesta 

train = sample( 1 : nrow( x ) , nrow( x ) / 2 )  # escoge 50% de los datos para entrenamiento
test = (-train) 
y.test = y[test]

```

Calculammos el error para toda la poblacion. Para poder calcular R2 de los modelos

```{r}

value_y = swiss[test,1]
sst <- sum((value_y - mean(value_y))^2)

```
Calculamos el modelo utilizando una regresion lineal sobre la data de entrenamiento, este modelo sera nuestra linea base.

```{r}

lm2 = lm(Fertility~., swiss[train,])
summary(lm2)
lm_predicted = as.numeric(predict(lm2, swiss[test,-1]))
sse_lm <- sum((lm_predicted - value_y)^2)

rsq_lm = 1 - sse_lm / sst
rsq_lm

```
Utilizamos la tecnica de regresion Ridge para calcular un lambda que pueda mejorar la performance del modelo.

```{r}

grid_ridge = 10 ^ seq ( 10, -2, length=100)  #grid de 100 valores para lambda (de 10^10 a 10^{-2})
ridge.mod = glmnet( x , y , alpha=0, lambda=grid_ridge) #alpha= 0 => regresion ridge
ridge.mod
#vamos a escoger lambda usando validaci√≥n cruzada (5-fold cross validation) para la regresi√≥n lasso 
cv.out_ridge = cv.glmnet( x[ train , ], y [ train ], alpha=0, nfolds=5)
plot(cv.out_ridge, main="Ridge regression") # Traza la curva de validacion cruzada y las curvas de desviacion estandar superior e inferior, en funci√≥n de los valores de lambda utilizados.
best_ridge_lambda = cv.out_ridge$lambda.min #escoge el mejor valor de lambda (el que alcanza el menor ECM - error cuadratico medio -  en la validacion cruzada)
best_ridge_lambda
#ECM del mejor modelo en el conjunto de prueba
ridge.pred = predict(ridge.mod, s=best_ridge_lambda, newx=x[test,])
mean(( ridge.pred - y.test ) ^ 2)  

# reajusta el modelo usando todos los dados y el mejor lambda
out_ridge = glmnet( x , y , alpha=0)
predict(out_ridge, type="coefficients", s = best_ridge_lambda) #muestra los coeficientes del modelo final

ridge_predicted = predict(out_ridge, as.matrix(swiss[test,-1]), s=best_ridge_lambda) 
ridge_predicted = as.numeric(ridge_predicted)
ridge_sse <- sum((ridge_predicted - value_y)^2)
rsq_ridge <- 1 - ridge_sse / sst
rsq_ridge

```


Utilizamos la regresion lasso para tambien evaluar el desempenio del modelo.

```{r}
grid_lasso = 10 ^ seq ( 10, -2, length=100) #grid de 100 valores para lambda (de 10^10 a 10^{-2})
lasso.mod = glmnet( x[ train, ], y[ train ], alpha=1, lambda=grid_lasso)
#vamos a escoger lambda usando validaci√≥n cruzada (5-fold cross validation) para la regresi√≥n lasso 
cv.out_lasso = cv.glmnet(x[train,],y[train],alpha=1,nfolds=5)
plot(cv.out_lasso,main="Lasso regression")
best_lasso_lambda = cv.out_lasso$lambda.min #igual a 20.12811
best_lasso_lambda

#ECM del mejor modelo en el conjunto de prueba
lasso.pred=predict(lasso.mod, s=best_ridge_lambda, newx=x[test,])
mean((lasso.pred - y.test) ^ 2) #igual a 70365.12

#reajusta el modelo usando todos los dados y el mejor lambda
out_lasso = glmnet( x , y , alpha=1, lambda=grid_lasso)
lasso.coef=predict(out_lasso, type="coefficients",s=best_lasso_lambda)
lasso.coef  ##muestra los coeficientes del modelo final
lasso.coef[lasso.coef!=0] ##muestra los coeficientes no nulos

lasso_predicted = predict(out_lasso, as.matrix(swiss[test,-1]), s=best_lasso_lambda) 
lasso_predicted = as.numeric(lasso_predicted)
lasso_sse <- sum((lasso_predicted - value_y) ^ 2)
rsq_lasso <- 1 - lasso_sse / sst
rsq_lasso

```
Como podemos apreciar utilizando la regresion RIDGE y LASSO nuestros modelos mejoran al poder explicar mucho mejor la varianza de la variable
dependiente, expresando mediante la medida $R^2$. 
```{r}

c(rsq_lm, rsq_ridge, rsq_lasso)

```


## **Pregunta 4** 
El conjunto de datos coleman contiene informacion sobre 20 escuelas de los estados de Mid-Atlantic y New England, extraidas de una poblacion estudiada por Coleman et al. (1966). Mosteller y Tukey (1977) analizan esta muestra que consiste en mediciones de las siguientes seis variables:

* salaryP: salarios del personal por alumno.
* fatherWc: porcentaje de padres con trabajo administrativo.
* sstatus: desviacion compuesta del estado socioecon√≥mico: significa para el tamanhio de la familia, la integridad de la familia, la educacion del padre, la educacion de la madre y los articulos del hogar 
* teacherSc: puntuaci√≥n media de la prueba verbal del maestro 
* motherLev: nivel educativo medio de la madre, una unidad equivale a dos a√±os escolares 
* Y: puntaje de la prueba verbal promedio (variable respuesta)

Este conjunto de datos se encuentra disponible en el paquete de R robustbase, para cargar el conjunto de datos use los siguientes comandos
library(robustbase) data("coleman") coleman.

**a) Ajuste un modelo de regresion por minimos cuadrados ordinarios e identifique las observaciones atipicas y reajuste el modelo de regresion eliminando las observaciones identificadas. Interprete los resultados.**

```{r LM1}
library(robustbase)
data("coleman")
str(coleman)
lm1 = lm(Y ~., data = coleman)  # Estimando por MÏnimos Cuadrados Ordinarios 
summary(lm1)


plot(coleman$Y, lm1$fitted.values)
abline(a=0,b=1, col="red")

plot(coleman$Y, lm1$residuals)
abline(a=0,b=0, col="red")

ncvTest(lm1) # heterocedasticidad

plot(cooks.distance(lm1))  # Identificando los outliers
```

A continuacion removemos los valores atipicos con la ayuda de la distancia de Cooks.

```{r LM2}

indices.cook <- which(cooks.distance(lm1) >= 4/nrow(coleman)) 
coleman <- coleman[-indices.cook, ]

lm2 <- lm(formula = Y ~ ., data = coleman)

summary(lm2)
```
Podemos apreciar como al retirar los outliers el modelo incrementa su $R^2$ significativamente.


**b) Ajuste un modelo de regresion robusta con las funciones objetivo hechas en clase y compare los resultados con el modelo del item a).**

A continuacion usar el estimador-M de Huber para el modelo de regresion de Duncan, utilizando la funciÛn rlm (modelo lineal robusto):


```{r} 
library(MASS) 
mod.robusto <- rlm(Y ~ ., data = coleman)
summary(mod.robusto)
```

En seguida extraemos y graficamos los pesos finales utilizados en el ajuste de mod.robusto. 

```{r, }
plot(mod.robusto$w, ylab="Huber Weight")
smallweights <- which(mod.robusto$w < 0.8)
showLabels(1:45, mod.robusto$w, rownames(coleman), method=smallweights, cex.=.6)
```


Etiquetando las observaciones con pesos inferiores a 0.8, se puede indicar que las escuelas 3, 17 y 19 se comportan como outliers o valores atÌpicos.

Adicionalmente, la funciÛn rlm, tambiÈn puede ajustar el modelo usando el estimador bisquare, especificando el argumento method ="MM" la funciÛn rlm solicita estimadores bisquare con valores iniciales determinados por una regresiÛn preliminar de influencia acotada. Como se indica a continuaciÛn:

```{r,}
mod.bisquare <- rlm(Y ~., data=coleman, method="MM")
summary(mod.bisquare)
```

Comparando los par·metros estimados con el $mod.robusto$ (mÈtodo de Huber), los coeficientes obtenidos con el modelo $mod.bisquare$ son mayores en todas las variables, gr·ficamente se tiene:

```{r}
plot(mod.bisquare$w, ylab="Bisquare Weight")
showLabels(1:45, mod.bisquare$w, rownames(coleman),method= which(mod.bisquare$w < 0.8), cex.=0.6)
```


Con la estimaciÛn bisquare se puede decir que, la ˙nica observaciÛn que se comporta valor atipico es el de la escuela 3, coencidiendo con el mod.robusto pero excluyendo a las escuelas 17 y 19.

**Comparando resultados**
Las estimaciones obtenidas mediante mÌnimos cuadrados indican valores extremos, con lm1 valores mÌnimos y con lm2 valores m·ximos, mientras que las estimaciones obtenidas con regresiÛn robusta indican valores intermedios, casÌ para toda las variables excepto para "teacherSc" donde los valores con regresiÛn robusta son mayores a los obtenidos con mÌnimos cuadrados.

## **pregunta 5**

En una empresa lechera se tienen varios silos para almacenar leche (cisternas de 60 000 L). Un aspecto critico para que se conserve la leche es la temperatura de almacenamiento. Se sospecha que en algunos silos hay problemas, por ello, durante cinco dias se decide registrar la temperatura a cierta hora critica. Obviamente la temperatura de un d√?a a otro es una fuente de variabilidad que podria impactar la variabilidad total. El conjunto de datos se encuentra en el archivo silos.txt.


```{r}

silos <- read.delim("silos.txt")

```

**a) En este problema, øcual es el factor de tratamiento y cual el factor de bloque?**

Factor de tratamiento son los silos de leche A, B, C, D y E.

Factor de bloques es dÌas de la semana. Los bloques son las variables adicionales que se incorporan de manera explÌcita en un experimento para lograr una mayor precision en la comparacion.

**b) Suponiendo un DBCA, formule las hip√≥tesis adecuadas y el modelo estadistico.**
La variable de respuesta es la temperatura de los silos en los que se almacena la leche. Para comparar la temperatura se plantea la siguiente hipotesis:

Modelo estadÌstico:
  $$Y_{ij}=\mu+\tau_i+y_j+\epsilon_{ij}$$ 
  
Donde $Y_{ij}$ corresponde a la mediciÛn segun el tratamiento y bloque, $\mu$ es la media poblacional de la temperatura, $\tau_i$ el efecto debido al tratamiento e $y_j$ es el efecto debido al bloque y $\epsilon_{ij}$ es el error aleatorio. Los errores se distribuyen de manera normal con
media cero y varianza constante y son independientes entre sÌ, $i=1, 2, ...k$ y $j=1, 2, ...b$.
  
  $$H_0: \mu_A=\mu_B=\mu_C=\mu_D=\mu_E=\mu$$
  $$H_1: \mu_i \neq \mu_j \quad \text{para alg˙n} \quad i \neq j=(A, B, C, D, E).$$
  
Donde:

  $H_0$ La hipÛtesis nula.

  $H_1$ La hipÛtesis alternativa.

$\mu_i$ La temperatura media de los silos.


**c) øHay diferencia entre los silos?**

```{r} 

tratamiento <- silos$Silo
bloque <- silos$Dia
mod <- lm(temperatura~tratamiento+as.factor(bloque), silos)
result <- anova(mod)
result
```

El valor p de los silos (tratamiento) de 0.6092 es mayor al nivel de significancia de 0.05, es decir que estadÌsticamente no hay diferencia y no se rechaza la hipÛtesis nula. Por lo que decimos que no hay diferencia significativa entre los silos.

**d) øLa temperatura de un dia a otro es diferente?**

**MÈtodo LSD (diferencia mÌnima significativa)**

Para investigar cu·les pares de medias son estadÌsticamente diferentes, se prueban los  pares posibles de hipÛtesis:

$H_0: \mu_A=\mu_B \quad \text{vs.} \quad H_1: \mu_A 	\neq \mu_B$

$H_0: \mu_A=\mu_C \quad \text{vs.} \quad H_1: \mu_A 	\neq \mu_C$

$H_0: \mu_A=\mu_D \quad \text{vs.} \quad H_1: \mu_A 	\neq \mu_D$

$H_0: \mu_B=\mu_C \quad \text{vs.} \quad H_1: \mu_B 	\neq \mu_C$

$H_0: \mu_B=\mu_D \quad \text{vs.} \quad H_1: \mu_B 	\neq \mu_D$

$H_0: \mu_C=\mu_D \quad \text{vs.} \quad H_1: \mu_C 	\neq \mu_D$

```{r}

mediat<-tapply(silos$temperatura,silos$Silo,mean)
mediat

difAB<-abs(mediat[1]-mediat[2])
difAC<-abs(mediat[1]-mediat[3])
difAD<-abs(mediat[1]-mediat[4])
difAE<-abs(mediat[1]-mediat[5])
difBC<-abs(mediat[2]-mediat[3])
difBD<-abs(mediat[2]-mediat[4])
difBE<-abs(mediat[2]-mediat[5])
difCD<-abs(mediat[3]-mediat[4])
difCE<-abs(mediat[3]-mediat[5])
difDE<-abs(mediat[4]-mediat[5])

CME <- 1.615
t <- qt(0.975,result$Df[3])

LSD <- t * sqrt(( 2 * CME ) / 4)
vecdif <- c(difAB,difAC,difAD,difAE,difBC,difBD,difBE,difCD,difCE,difDE)
nombres <- c("difAB","difAC","difAD","difAE","difBC","difBD","difBE","difCD","difCE","difDE")

for(i in 1:9)
{
  if(vecdif[i]>LSD)
    print(paste(nombres[i],"Significativa"))
  else
    print(paste(nombres[i],"No significativa"))
}

```

Se concluye que las diferencias entre tratamiento y bloques no son significativas.

**MÈtodo de Tukey**

```{r} 
amod<-aov(temperatura ~ Silo + as.factor(Dia), data = silos )
compmet<-glht(amod,linfct=mcp(Silo="Tukey"))
summary(compmet)
```

Se concluye lo mismo que con el mÈtodo LSD.

**MÈtodo de Dunnet**

```{r} 
amod<-aov(temperatura~Silo+as.factor(Dia), data = silos)
compmet_control <-glht(amod,linfct=mcp(Silo="Dunnett"))
summary(compmet_control)
```

Se corrobora la conclusiÛn de los mÈtodos LSD y Tuckey.

La temperatura de un dÌa a otro (bloques) no varia,  el valor p de 0.2460 es superior al nivel de significancia de 0.05. Lo anterior se comprueba con los mÈtodos de comparaciÛn de medias de tratamiento en el DBCA, LSD, Tuckey y Dunnet.

## **pregunta 6**

Se estudia el rendimiento de un proceso quimico. Se piensa que las dos variables mas importantes son la presion (psig) y la temperatura (grados centigrados). Se seleccionan tres niveles de cada factor y se lleva a cabo un experimento factorial con dos replicas. Los datos del rendimiento se encuentran disponibles en el archivo rendimiento.txt.

Nota: recuerde colocar la temperatura y la presion en R as.factor().

```{r}
Rendimiento <- read.table("rendimiento.txt",header=T)
Rendimiento$temperatura = as.factor(Rendimiento$temperatura)
Rendimiento$presion = as.factor(Rendimiento$presion)
str(Rendimiento)

```

**a) Suponiendo un anaisis factorial formule las hipotesis adecuadas y el modelo estadistico.**

```{r}
Rendimiento
```

Hipotesis de interes:

$$H_0 : \text{efecto de temperatura (A)} = 0$$
$$H_0 : \text{efecto de temperatura (A)} \neq 0$$

$$H_0 : \text{efecto de presisn (B)} = 0$$
$$H_0 : \text{efecto de presisn (B)} \neq 0$$


$$H_0 : \text{temperatura x presion (AB)} = 0$$
$$H_0 : \text{temperatura x presion (AB)} \neq 0$$


Estas hipstesis tambien se pueden plantear con los efectos descritos en el modelo:

$$H_0 : \alpha_1 = \alpha_2=...=\alpha_3=0$$
$$H_1 : \alpha_i \neq 0 \quad \text{para algun i}$$

$$H_0 : \beta_1 = \beta_2=...=\beta_3=0$$
$$H_1 : \beta_j \neq 0 \quad \text{para algun j}$$

$$H_0 : (\alpha\beta)_{ij} =0 \quad \text{para todo ij}$$
$$H_0 : (\alpha\beta)_{ij} \neq 0 \quad \text{para algun ij}$$

**b) Los factores y la interaccion de los factores son significativas?**


```{r } 

mod <- lm(rendimiento ~ temperatura + presion + temperatura*presion, data = Rendimiento)
summary(mod)

result <-anova(mod)
result
```

En el analisis de varianza se concluye que los 2 efectos A: temperatura, B: presion influyen en el rendimiento, dado que sus efectos resultan significativos. Sin embargo, la interacion entre los factores no es significativa. 

**c) øBajo que condiciones deberia operarse este proceso?**

```{r } 

with(Rendimiento,(interaction.plot(presion, temperatura, rendimiento, type = "b",
                              pch = c(18,24,22), leg.bty = "o",
                              main = "Efecto de interaccion presion x temperatura",
                              xlab = "presion",ylab = "rendimiento")))
```


En el grafico las temperaturas con sus tres niveles. La significancia de la interaccion detectada por el ANOVA se observa en el hecho de que las lineas en la figura tienen pendientes diferentes, lo que indicara la no interaccion de sus factores. Como lo que interesa es maximizar la variable de respuesta, se selecciona Temperatura = 170, Presion =  215  con lo que se maximiza.

## **pregunta 7**

Se realiza un estudio para determinar si existe una diferencia en la resistencia de una fibra de monofilamento producida por tres maquinas diferentes. Se cree que la resistencia de una fibra en libras depende del diametro (o grosor) en $10^{-3}$ pulgadas. Los datos se encuentran en el archivo *fibra.txt*

* a) Realice un diagrama de dispersion entre la resistencia y el diametro. Interprete los resultados.  
* b) Suponiendo un anaisis de covariancia formule las hipotesis adecuadas y el modelo estadistico. 
* c) øLas maquinas influyen en la resistencia del monofilamento?


**a) Realice un diagrama de dispersi√≥n entre la resistencia y el di√°metro. Interprete los resultados**


Diagrama de dispersion

```{r}
datos_fibra <-  read.table("fibra.txt", header=TRUE)

plot(x = datos_fibra[ , 2],  y = datos_fibra[ , 1],  col = datos_fibra[ , 3], xlab = "diametro 10^-3 pulgadas", ylab = "resitencia")

abline(lm(formula = resitencia ~ diametro, data = datos_fibra),  col = 4,  lwd = 2)

```

Hay una relacion lineal positiva entre la resistencia y el diametro de los microfilamentos.

**B) Suponiendo un analisis de covariancia formule las hipotesis adecuadas y el modelo estadistico.**

Como se quiere averiguar si la resistencia es afectada por la maquina que desarrollo el monofilamento, se considera la maquina procedente como los tratamientos. De otro lado, suponiendo un analisis de covarianza se tomara como covariable al diametro de cada observacion de microfilamento.

Modelo:  

- Y, variable de respuesta del tratamiento: Resistencia
- Tratamiento : Es el tratamiento dado por la Maquina
- X, covariable: diametro

Supuestos:  

1. La variable de diametro ha sido medida sin error y no es afectada por los tratamientos
2. Tanto X como Y tienen varianzas homogeneas en los tratamientos
3. X e Y tienen distribucion normal
4. La regresion de X sobre Y es lineal
5. Los errores son identicamente distribuidos con distribuci√≥n $\varepsilon \sim N(0,\sigma^2)$

**C) øLas maquinas influyen en la resistencia del monofilamento?**

Cargamos la libreria que contiene la funcion del Anova


Creamos un modelo lineal entre la variable respuesta vs. la covariable y el tratamiento. Luego utilizamos Anova para observar los resultados

```{r}
lm.pregunta7 <- lm(resitencia ~ diametro + maquina, data = datos_fibra)
(anova.pregunta7 <-Anova(lm.pregunta7, type="III"))
```

De acuerdo a los resultados, apreciamos que las diferencias en los tratamientos (maquinas) no son significativas por lo que no influyen en la resistencia de los microfilamentos. Por otra parte, se observa que la covariable de diametro si influye en el valor de resistencia de forma significativa.
