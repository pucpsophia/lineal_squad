---
title: "Modelos Lineales"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(MASS)
library(car)
library("PerformanceAnalytics")
library(lmtest)
library(glmnet)

# set working directory
#setwd("/Users/gvalderrama/Documents/pucp/lineal_squad/entregables/greg")
#setwd("/Users/gregory/Documents/pucp/lineal_squad/entregables/greg")
setwd("F:/lineal_squad/entregables/greg")

```

# *Gregory Valderrama - 20133303* 

## **Pregunta 1** 
Demuestre que la varianza del estimador de Œ≤ por m√≠nimos cuadrados generalizados es $Var(\hat{B})=\sigma^2(X^TV^{-1}X)^{-1}$
realize la demostracion paso a paso detallando las propiedades utilizadas.

## **Pregunta 2** 
Suponga que deseamos ajustar un modelo de regresi√≥n sin intercepto con m√≠nimos cuadrados ponderados. Suponer que las observaciones son no correlacionadas, pero que tienen varianzas desiguales.

a) Deducir una f√≥rmula general para el estimador de $\beta$ por m√≠nimos cuadrados ponderados. 

b) ¬øCu√°l es la varianza del estimador del √≠tem anterior?

## **Pregunta 3** 

El conjunto de datos sobre la medici√≥n estandarizada de la fecundidad e indicadores socioecon√≥micos para cada una de las 47 provincias franc√≥fonas de Suiza alrededor del a√±o 1888 se encuentran disponibles en R bajo el nombre swiss. Este conjunto de datos cuenta con 47 observaciones sobre 6 variables, cada una de las cuales est√° en porcentaje, es decir, en [0, 100].
Realice un an√°lisis descriptivo y luego ajuste un modelo de regresi√≥n lineal considerando como variable respuesta la variable fertilidad y el resto como covariables. Verifique si el modelo cumple con los supuestos. Corrija el problema de multicolinealidad con las t√©cnicas estudiadas en clase e interprete los resultados del modelo final. Para cargar el conjunto de datos use el comando data(swiss) en el R.

### *Descripcion de datos*

* $\textbf{Fertility }$ Ig. medida com?n de fertilidad estandarizada

* $\textbf{Agriculture }$ % de hombres involucrados en la agricultura como ocupacion

* $\textbf{Examination }$ % de reclutas que reciben la calificacion mas alta en el examen del ejercito

* $\textbf{Education }$ % educacion mas all? de la escuela primaria para reclutas.

* $\textbf{Catholic }$ % 'catolico' (a diferencia de 'protestante').

* $\textbf{Infant.Mortality }$ nacidos vivos que viven menos de 1 anhio.

```{r} 
data(swiss)
colnames(swiss)
str(swiss)
summary(swiss)
```

#### *Regresion lineal*

```{r }
lm1 <- lm(formula = Fertility ~ ., data = swiss)
summary(lm1)

```

Lo primera observacion es que tenemos un buen modelo y hay varias variables (la mayoria) con una buena
significancia. Un punto que no deberia suceder pero siempre ocurre es que el intercepto no es 0, esto podria
causar que los valores estimados de Fertilidad salgan menores a 0, lo cual en la realidad seria imposible pues no
se puede recaudar negativo.

```{r code4, exercise=TRUE}
lm1 <- lm(formula = Fertility ~ ., data = swiss)
lm1$coefficients
```
Lo que significan estos coeficientes, por ejemplo el ?ltimo de la lista Infant.Mortality nos dice que si todas las otros
otros regresores se mantuvieran constantes y solamente ese cambiara en una unidad, el Fertility se ver?a
afectado en 1.07705. 


#### *Analizado los graficos de la regresion, Valores reales vs valores estimados*

```{r}
lm1 <- lm(formula = Fertility ~ ., data = swiss)
plot(lm1$fitted.values, swiss$Fertility)
abline(0, 1, col = 2)
```

#### Supuestos

**Grafico de los residuos - homocedasticidad**

La figura nos permite evaluar la hipotesis de homocedasticidad de los residuos,
sera aceptable cuando la anchura horizontal del grafico se mantenga razonablemente
constante. 

Si el p-value del test de Breusch-Pagan es mayor que 0.05 entonces aceptamos la hipotesis
nula (la varianza de todos los grupos son iguales) y decimos que cumple el
supuesto de homocedasticidad, caso contrario no se cumple el supuesto de homocedasticidad
de varianzas. Podemos ver que se acepta la homocedasticidad.


```{r}
lm1 <- lm(formula = Fertility ~ ., data = swiss)

ncvTest(lm1)

plot(lm1, which=c(3))
```


**Efecto de las variables independientes en la variable dependiente es lineal**

```{r}
par(mfrow=c(1,1))
plot(lm1, which=c(1))

```

**Normalidad de los errores**

Los errores residuales son normales y normalmente distribuidos con media cero.
Aplicando el test de Shapiro-Wilk se probara si se cumple o no el supuesto de normalidad de los
residuos. Con un valor de 0.93 probamos la normalidad de los datos.


```{r}

shapiro.test(lm1$residuals)

par(mfrow=c(1,1))
plot(lm1, which=c(2))

```
**Los errores no estan correlacionados**

Autocorrelacion significa la correlacion de los valores de una misma variable ordenados en el tiempo (con datos de
series temporales) o en el espacio (con datos espaciales). 

```{r}

dwtest(lm1)

par(mfrow=c(1,1))
plot(lm1, which=c(3))

```


**Multicolinealidad de los regresores es minima**

Buscaremos variables que esten correlacionadas con las demas y que, por ello, no esten aportando mas al modelo y que podrian estar distorsionando las predicciones generando overfitting.

```{r}

vif(lm1)
chart.Correlation(swiss, histogram=FALSE, pch=19)

```

Como podemos apreciar existe una correlacion entre las variables Examination y Education, para revizar la performance de la prediccion
del modelo, compararemos el $R^2$ con los metodos RIDGE y LASSO para ver si podemos obtener una mejor precision. Dividimos el conjunto de datos en un grupo de entrenamiento y otro de validacion. 

```{r}

set.seed(1)

x = model.matrix(Fertility~., swiss)[, -c(1)] # matriz de covariables
y = swiss$Fertility                           # vector respuesta 

train = sample( 1 : nrow( x ) , nrow( x ) / 2 )  # escoge 50% de los datos para entrenamiento
test = (-train) 
y.test = y[test]

```

Calculammos el error para toda la poblacion. Para poder calcular R2 de los modelos

```{r}

value_y = swiss[test,1]
sst <- sum((value_y - mean(value_y))^2)

```
Calculamos el modelo utilizando una regresion lineal sobre la data de entrenamiento, este modelo sera nuestra linea base.

```{r}

lm2 = lm(Fertility~., swiss[train,])
summary(lm2)
lm_predicted = as.numeric(predict(lm2, swiss[test,-1]))
sse_lm <- sum((lm_predicted - value_y)^2)

rsq_lm = 1 - sse_lm / sst
rsq_lm

```
Utilizamos la tecnica de regresion Ridge para calcular un lambda que pueda mejorar la performance del modelo.

```{r}

grid_ridge = 10 ^ seq ( 10, -2, length=100)  #grid de 100 valores para lambda (de 10^10 a 10^{-2})
ridge.mod = glmnet( x , y , alpha=0, lambda=grid_ridge) #alpha= 0 => regresion ridge
ridge.mod
#vamos a escoger lambda usando validaci√≥n cruzada (5-fold cross validation) para la regresi√≥n lasso 
cv.out_ridge = cv.glmnet( x[ train , ], y [ train ], alpha=0, nfolds=5)
plot(cv.out_ridge, main="Ridge regression") # Traza la curva de validacion cruzada y las curvas de desviacion estandar superior e inferior, en funci√≥n de los valores de lambda utilizados.
best_ridge_lambda = cv.out_ridge$lambda.min #escoge el mejor valor de lambda (el que alcanza el menor ECM - error cuadratico medio -  en la validacion cruzada)
best_ridge_lambda
#ECM del mejor modelo en el conjunto de prueba
ridge.pred = predict(ridge.mod, s=best_ridge_lambda, newx=x[test,])
mean(( ridge.pred - y.test ) ^ 2)  

# reajusta el modelo usando todos los dados y el mejor lambda
out_ridge = glmnet( x , y , alpha=0)
predict(out_ridge, type="coefficients", s = best_ridge_lambda) #muestra los coeficientes del modelo final

ridge_predicted = predict(out_ridge, as.matrix(swiss[test,-1]), s=best_ridge_lambda) 
ridge_predicted = as.numeric(ridge_predicted)
ridge_sse <- sum((ridge_predicted - value_y)^2)
rsq_ridge <- 1 - ridge_sse / sst
rsq_ridge

```


Utilizamos la regresion lasso para tambien evaluar el desempenio del modelo.

```{r}
grid_lasso = 10 ^ seq ( 10, -2, length=100) #grid de 100 valores para lambda (de 10^10 a 10^{-2})
lasso.mod = glmnet( x[ train, ], y[ train ], alpha=1, lambda=grid_lasso)
#vamos a escoger lambda usando validaci√≥n cruzada (5-fold cross validation) para la regresi√≥n lasso 
cv.out_lasso = cv.glmnet(x[train,],y[train],alpha=1,nfolds=5)
plot(cv.out_lasso,main="Lasso regression")
best_lasso_lambda = cv.out_lasso$lambda.min #igual a 20.12811
best_lasso_lambda

#ECM del mejor modelo en el conjunto de prueba
lasso.pred=predict(lasso.mod, s=best_ridge_lambda, newx=x[test,])
mean((lasso.pred - y.test) ^ 2) #igual a 70365.12

#reajusta el modelo usando todos los dados y el mejor lambda
out_lasso = glmnet( x , y , alpha=1, lambda=grid_lasso)
lasso.coef=predict(out_lasso, type="coefficients",s=best_lasso_lambda)
lasso.coef  ##muestra los coeficientes del modelo final
lasso.coef[lasso.coef!=0] ##muestra los coeficientes no nulos

lasso_predicted = predict(out_lasso, as.matrix(swiss[test,-1]), s=best_lasso_lambda) 
lasso_predicted = as.numeric(lasso_predicted)
lasso_sse <- sum((lasso_predicted - value_y) ^ 2)
rsq_lasso <- 1 - lasso_sse / sst
rsq_lasso

```
Como podemos apreciar utilizando la regresion RIDGE y LASSO nuestros modelos mejoran al poder explicar mucho mejor la varianza de la variable
dependiente, expresando mediante la medida $R^2$. 
```{r}

c(rsq_lm, rsq_ridge, rsq_lasso)

```


## **Pregunta 4** 
El conjunto de datos coleman contiene informacion sobre 20 escuelas de los estados de Mid-Atlantic y New England, extraidas de una poblacion estudiada por Coleman et al. (1966). Mosteller y Tukey (1977) analizan esta muestra que consiste en mediciones de las siguientes seis variables:

* salaryP: salarios del personal por alumno.
* fatherWc: porcentaje de padres con trabajo administrativo.
* sstatus: desviaci√≥n compuesta del estado socioecon√≥mico: significa para el tama√±o de la familia, la integridad de la familia, la educacion del padre, la educacion de la madre y los articulos del hogar 
* teacherSc: puntuaci√≥n media de la prueba verbal del maestro 
* motherLev: nivel educativo medio de la madre, una unidad equivale a dos a√±os escolares 
* Y: puntaje de la prueba verbal promedio (variable respuesta)

Este conjunto de datos se encuentra disponible en el paquete de R robustbase, para cargar el conjunto de datos use los siguientes comandos
library(robustbase) data("coleman") coleman.

**a) Ajuste un modelo de regresion por minimos cuadrados ordinarios e identifique las observaciones atipicas y reajuste el modelo de regresion eliminando las observaciones identificadas. Interprete los resultados.**

```{r LM1}
library(robustbase)
data("coleman")
str(coleman)
lm1 = lm(Y ~., data = coleman)  # Estimando por MÏnimos Cuadrados Ordinarios (MCO) con todas las variables
summary(lm1)


plot(coleman$Y, lm1$fitted.values)
abline(a=0,b=1, col="red")

plot(coleman$Y, lm1$residuals)
abline(a=0,b=0, col="red")

ncvTest(lm1) # Presencia de heterocedasticidad

plot(cooks.distance(lm1))  # Identificando los outliers
```

A continuacion removemos los valores atipicos con la ayuda de la distancia de Cooks.

```{r LM2}

indices.cook <- which(cooks.distance(lm1) >= 4/nrow(coleman)) 
coleman <- coleman[-indices.cook, ]

lm2 <- lm(formula = Y ~ ., data = coleman)

summary(lm2)
```
Podemos apreciar como al retirar los outliers el modelo incrementa su $R^2$ significativamente.


**b) Ajuste un modelo de regresion robusta con las funciones objetivo hechas en clase y compare los resultados con el modelo del item a).**

A continuacion usar el estimador-M de Huber para el modelo de regresion de Duncan, utilizando la funciÛn rlm (modelo lineal robusto):


```{r} 
library(MASS) 
mod.robusto <- rlm(Y ~ ., data = coleman)
summary(mod.robusto)
```

En seguida extraemos y graficamos los pesos finales utilizados en el ajuste de mod.robusto. 

```{r, }
plot(mod.robusto$w, ylab="Huber Weight")
smallweights <- which(mod.robusto$w < 0.8)
showLabels(1:45, mod.robusto$w, rownames(coleman), method=smallweights, cex.=.6)
```


Etiquetando las observaciones con pesos inferiores a 0.8, se puede indicar que las escuelas 3, 17 y 19 se comportan como outliers o valores atÌpicos.

Adicionalmente, la funciÛn rlm, tambiÈn puede ajustar el modelo usando el estimador bisquare, especificando el argumento method ="MM" la funciÛn rlm solicita estimadores bisquare con valores iniciales determinados por una regresiÛn preliminar de influencia acotada. Como se indica a continuaciÛn:

```{r,}
mod.bisquare <- rlm(Y ~., data=coleman, method="MM")
summary(mod.bisquare)
```

Comparando los par·metros estimados con el $mod.robusto$ (mÈtodo de Huber), los coeficientes obtenidos con el modelo $mod.bisquare$ son mayores en todas las variables, gr·ficamente se tiene:

```{r}
plot(mod.bisquare$w, ylab="Bisquare Weight")
showLabels(1:45, mod.bisquare$w, rownames(coleman),method= which(mod.bisquare$w < 0.8), cex.=0.6)
```


Con la estimaciÛn bisquare se puede decir que, la ˙nica observaciÛn que se comporta valor atipico es el de la escuela 3, coencidiendo con el mod.robusto pero excluyendo a las escuelas 17 y 19.

**Comparando resultados**
Las estimaciones obtenidas mediante mÌnimos cuadrados indican valores extremos, con lm1 valores mÌnimos y con lm2 valores m·ximos, mientras que las estimaciones obtenidas con regresiÛn robusta indican valores intermedios, casÌ para toda las variables excepto para "teacherSc" donde los valores con regresiÛn robusta son mayores a los obtenidos con mÌnimos cuadrados.

## **pregunta 5**

En una empresa lechera se tienen varios silos para almacenar leche (cisternas de 60 000 L). Un aspecto critico para que se conserve la leche es la temperatura de almacenamiento. Se sospecha que en algunos silos hay problemas, por ello, durante cinco dias se decide registrar la temperatura a cierta hora critica. Obviamente la temperatura de un d√≠a a otro es una fuente de variabilidad que podria impactar la variabilidad total. El conjunto de datos se encuentra en el archivo silos.txt.

* a) En este problema, ¬øcu√°l es el factor de tratamiento y cu√°l el factor de bloque? 
* b) Suponiendo un DBCA, formule las hip√≥tesis adecuadas y el modelo estad√≠stico. 
* c) ¬øHay diferencia entre los silos? d) ¬øLa temperatura de un d√≠a a otro es diferente?


## **pregunta 6**

Se estudia el rendimiento de un proceso qu√≠mico. Se piensa que las dos variables m√°s importantes son la presi√≥n (psig) y la temperatura (grados cent√≠grados). Se seleccionan tres niveles de cada factor y se lleva a cabo un experimento factorial con dos r√©plicas. Los datos del rendimiento se encuentran disponibles en el archivo rendimiento.txt.

* a) Suponiendo un an√°lisis factorial formule las hip√≥tesis adecuadas y el modelo estad√≠stico. 
* b) ¬øLos factores y la interacci√≥n de los factores son significativas? 
* c) ¬øBajo qu√© condiciones deber√≠a operarse este proceso?

Nota: recuerde colocar la temperatura y la presi√≥n en R as.factor().

## **pregunta 7**

Se realiza un estudio para determinar si existe una diferencia en la resistencia de una fibra de monofilamento producida por tres maquinas diferentes. Se cree que la resistencia de una fibra en libras depende del diametro (o grosor) en $10^{-3}$ pulgadas. Los datos se encuentran en el archivo *fibra.txt*

* a) Realice un diagrama de dispersion entre la resistencia y el diametro. Interprete los resultados.  
* b) Suponiendo un anaisis de covariancia formule las hipotesis adecuadas y el modelo estadistico. 
* c) øLas maquinas influyen en la resistencia del monofilamento?


**a) Realice un diagrama de dispersi√≥n entre la resistencia y el di√°metro. Interprete los resultados**


Diagrama de dispersion

```{r}
datos_fibra <-  read.table("fibra.txt", header=TRUE)

plot(x = datos_fibra[ , 2],  y = datos_fibra[ , 1],  col = datos_fibra[ , 3], xlab = "diametro 10^-3 pulgadas", ylab = "resitencia")

abline(lm(formula = resitencia ~ diametro, data = datos_fibra),  col = 4,  lwd = 2)

```

Hay una relacion lineal positiva entre la resistencia y el diametro de los microfilamentos.

**B) Suponiendo un analisis de covariancia formule las hipotesis adecuadas y el modelo estadistico.**

Como se quiere averiguar si la resistencia es afectada por la maquina que desarrollo el monofilamento, se considera la maquina procedente como los tratamientos. De otro lado, suponiendo un analisis de covarianza se tomara como covariable al diametro de cada observacion de microfilamento.

Modelo:  

- Y, variable de respuesta del tratamiento: Resistencia
- Tratamiento : Es el tratamiento dado por la Maquina
- X, covariable: diametro

Supuestos:  

1. La variable de diametro ha sido medida sin error y no es afectada por los tratamientos
2. Tanto X como Y tienen varianzas homogeneas en los tratamientos
3. X e Y tienen distribucion normal
4. La regresion de X sobre Y es lineal
5. Los errores son identicamente distribuidos con distribuci√≥n $\varepsilon \sim N(0,\sigma^2)$

**C) øLas maquinas influyen en la resistencia del monofilamento?**

Cargamos la libreria que contiene la funcion del Anova


Creamos un modelo lineal entre la variable respuesta vs. la covariable y el tratamiento. Luego utilizamos Anova para observar los resultados

```{r}
lm.pregunta7 <- lm(resitencia ~ diametro + maquina, data = datos_fibra)
(anova.pregunta7 <-Anova(lm.pregunta7, type="III"))
```

De acuerdo a los resultados, apreciamos que las diferencias en los tratamientos (maquinas) no son significativas por lo que no influyen en la resistencia de los microfilamentos. Por otra parte, se observa que la covariable de diametro si influye en el valor de resistencia de forma significativa.
